{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45f0459e-91aa-4cd7-9d14-d111b7c2f6f2",
   "metadata": {},
   "source": [
    "## Neural Network Project: Constructing a CNN Auto-Encoder for Traffic Data Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c28959-f4d0-4ed9-a082-906da936aae0",
   "metadata": {},
   "source": [
    "#### 1. Installing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77535bdc-4636-40ec-beb3-b5c445079372",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install tensorflow tensorflow-datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e942f3f-73ed-4e70-b1da-c30724bdb704",
   "metadata": {},
   "source": [
    "#### 2. Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbc72f17-f5ec-4583-8b36-efd3e60481fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, UpSampling2D, Conv2DTranspose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c363bf-1af9-4687-964b-e999452b80cb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Building the image data set\n",
    "(train_ds, val_ds) = tf.keras.utils.image_dataset_from_directory('Image_Data', labels = None, color_mode = 'grayscale', batch_size = 32, seed = 365,\n",
    "                                                   image_size = (200, 200), shuffle = True, validation_split = 0.25, subset = 'both')\n",
    "\n",
    "## Scaling the data to be between 0 and 1\n",
    "train_ds = train_ds.map(lambda x:(x/255))\n",
    "val_ds = val_ds.map(lambda x:(x/255))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc53651-6496-438e-aefa-fab8a630d133",
   "metadata": {},
   "source": [
    "#### 3. Loading images from directory into tf.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7d7eaca-cb2b-43a5-bf7f-0da75d928bfc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 512 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "## Building the image data set\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory('Image_Data', labels = None, color_mode = 'grayscale', batch_size = None, \n",
    "                                                       seed = 365, image_size = (200, 200), shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b867fd0-3c29-4d29-aa1d-f29d2ef50775",
   "metadata": {},
   "source": [
    "#### 4. Image data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf151ad2-e940-4121-a5cb-10f59925700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scaling the data to be between 0 and 1\n",
    "train_ds = train_ds.map(lambda x:(x/255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f98b9ecb-712b-4160-9ea4-8d27fe9be1cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Converting tf.Dataset objects to numpy arrays\n",
    "def dataset_to_numpy(ds):\n",
    "    images = []\n",
    "    for i, image in enumerate(tfds.as_numpy(ds)): \n",
    "        images.append(image)\n",
    "    return np.array(images)\n",
    "\n",
    "train = dataset_to_numpy(train_ds)[0:384]\n",
    "val = dataset_to_numpy(train_ds)[384:512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52510726-e21a-4ef8-8c71-6cf7a16652b0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data_iterator = train_ds.as_numpy_iterator()\n",
    "#batch = data_iterator.next()\n",
    "batch = train.next()\n",
    "fig, ax = plt.subplots(ncols=4, figsize=(14,14))\n",
    "for idx, img in enumerate(batch[:4]):\n",
    "    ax[idx].imshow(img, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a9b6d0-ef6b-4864-acf2-b7599b871d4e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = tfds.as_numpy(train_ds)\n",
    "val = tfds.as_numpy(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5949df9-e2c4-4ad8-aff1-a49e27203344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1b052e-5111-4ce1-9e50-8225d88d3d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6736b4ce-dd66-461f-bd5d-4cb3e819a405",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Defining a numpy iterator to look through data batches\n",
    "data_interator = train_ds.as_numpy_iterator()\n",
    "\n",
    "## Splitting the data into training, validation, and testing\n",
    "train_size = 3050\n",
    "val_size = 1000\n",
    "#test_size = \n",
    "\n",
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "#test = data.skip(train_size + val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e28c6f-e1e1-48de-8883-088c09267f17",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Defining a numpy iterator to look through data batches\n",
    "data_interator = train_ds.as_numpy_iterator()\n",
    "\n",
    "## Grabbing the first batch from the data set\n",
    "batch = data_interator.next()\n",
    "\n",
    "## Visualizing some images from the first batch\n",
    "fig, axs = plt.subplots(ncols = 4, figsize = (14, 14))\n",
    "for i, img in enumerate(batch[:4]):\n",
    "    axs[i].imshow(batch[i], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf6db00-7bdc-445b-a98e-156a5a6500db",
   "metadata": {},
   "source": [
    "#### 5. Constructing the auto-encoder architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3f2996c-c234-4712-81ba-bede5572931e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Defining the Sequential model\n",
    "autoencoder = Sequential(name = 'Autoencoder')\n",
    "\n",
    "## Input Layer\n",
    "autoencoder.add(Input(shape=(200, 200, 1), name = 'Input'))\n",
    "\n",
    "## Convo-Pooling Layer 1\n",
    "autoencoder.add(Conv2D(20, (9,9), 1, activation = 'relu', data_format = 'channels_last', name = 'Conv_1'))\n",
    "autoencoder.add(MaxPooling2D(pool_size = (4,4), strides = None, padding = 'valid',  data_format = 'channels_last', name = 'Max_1'))\n",
    "\n",
    "## Convo-Pooling Layer 2\n",
    "autoencoder.add(Conv2D(60, (9,9), 1, activation = 'relu',  data_format = 'channels_last', name = 'Conv_2'))\n",
    "autoencoder.add(MaxPooling2D(pool_size = (2,2), strides = None, padding = 'valid',  data_format = 'channels_last', name = 'Max_2'))\n",
    "\n",
    "## Convo-Pooling Layer 3\n",
    "autoencoder.add(Conv2D(180, (9,9), 1, activation = 'relu',  data_format = 'channels_last', name = 'Conv_3'))\n",
    "autoencoder.add(MaxPooling2D(pool_size = (2,2), strides = None, padding = 'valid',  data_format = 'channels_last', name = 'Max_3'))\n",
    "\n",
    "## Fully-Connected Layer\n",
    "autoencoder.add(Dense(180, activation = 'relu', use_bias = False, name = 'Dense'))\n",
    "\n",
    "## Up Convo-Pooling Layer 1\n",
    "autoencoder.add(UpSampling2D(size = (2,2), data_format = 'channels_last', name = 'Up_Max_1'))\n",
    "autoencoder.add(Conv2DTranspose(180, (9,9), activation = 'relu', padding = 'valid', data_format = 'channels_last', name = 'Up_Conv_1'))\n",
    "\n",
    "##Up Convo-Pooling Layer 2\n",
    "autoencoder.add(UpSampling2D(size = (2,2), data_format = 'channels_last', name = 'Up_Max_2'))\n",
    "autoencoder.add(Conv2DTranspose(60, (9,9), activation = 'relu', padding = 'valid', data_format = 'channels_last', name = 'Up_Conv_2'))\n",
    "\n",
    "## Up Convo-Pooling Layer 3\n",
    "autoencoder.add(UpSampling2D(size = (4,4), data_format = 'channels_last', name = 'Up_Max_3'))\n",
    "autoencoder.add(Conv2DTranspose(20, (9,9), activation = 'relu', padding = 'valid', data_format = 'channels_last', name = 'Up_Conv_3'))\n",
    "\n",
    "## Output Layer\n",
    "autoencoder.add(Conv2D(1, (3, 3), activation = 'sigmoid', padding = 'same',  data_format = 'channels_last', name = 'Output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7540257a-b4fc-40c2-aecc-c8177acafdf0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Conv_1 (Conv2D)             (None, 192, 192, 20)      1640      \n",
      "                                                                 \n",
      " Max_1 (MaxPooling2D)        (None, 48, 48, 20)        0         \n",
      "                                                                 \n",
      " Conv_2 (Conv2D)             (None, 40, 40, 60)        97260     \n",
      "                                                                 \n",
      " Max_2 (MaxPooling2D)        (None, 20, 20, 60)        0         \n",
      "                                                                 \n",
      " Conv_3 (Conv2D)             (None, 12, 12, 180)       874980    \n",
      "                                                                 \n",
      " Max_3 (MaxPooling2D)        (None, 6, 6, 180)         0         \n",
      "                                                                 \n",
      " Dense (Dense)               (None, 6, 6, 180)         32400     \n",
      "                                                                 \n",
      " Up_Max_1 (UpSampling2D)     (None, 12, 12, 180)       0         \n",
      "                                                                 \n",
      " Up_Conv_1 (Conv2DTranspose)  (None, 20, 20, 180)      2624580   \n",
      "                                                                 \n",
      " Up_Max_2 (UpSampling2D)     (None, 40, 40, 180)       0         \n",
      "                                                                 \n",
      " Up_Conv_2 (Conv2DTranspose)  (None, 48, 48, 60)       874860    \n",
      "                                                                 \n",
      " Up_Max_3 (UpSampling2D)     (None, 192, 192, 60)      0         \n",
      "                                                                 \n",
      " Up_Conv_3 (Conv2DTranspose)  (None, 200, 200, 20)     97220     \n",
      "                                                                 \n",
      " Output (Conv2D)             (None, 200, 200, 1)       181       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,603,121\n",
      "Trainable params: 4,603,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Compiling the Sequential model\n",
    "autoencoder.compile(optimizer = 'adam', loss = tf.losses.MeanSquaredError())\n",
    "\n",
    "## Printing a model summary\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5da3f57-a9c0-4875-bd5e-4ebb9371e0f2",
   "metadata": {},
   "source": [
    "#### 6. Fitting the autoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e1bbf2-5937-4da6-a5a8-ab0df693ac1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 21:31:28.324296: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 61440000 exceeds 10% of free system memory.\n",
      "2023-03-31 21:31:28.380950: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 61440000 exceeds 10% of free system memory.\n",
      "2023-03-31 21:31:29.978489: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 94371840 exceeds 10% of free system memory.\n",
      "2023-03-31 21:31:32.423238: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 283115520 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "autoencoder.fit(train, train, epochs = 5, batch_size = 32, shuffle = True, validation_data = (val, val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e187d07-2017-4800-aaef-c1ff32538299",
   "metadata": {},
   "source": [
    "#### 7. Predicting on the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bb8a1a-1d38-4bd1-9d4c-1e30d137a425",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
